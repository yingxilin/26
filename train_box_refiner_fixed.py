#!/usr/bin/env python3
"""
Box Refinement è®­ç»ƒè„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤äº†æ··åˆç²¾åº¦è®­ç»ƒã€æŸå¤±è®¡ç®—å’Œç‰¹å¾ç¼“å­˜çš„é—®é¢˜
"""

import os
import sys
import time
import yaml
import argparse
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

# æ·»åŠ modulesç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))

from modules.box_refinement import BoxRefinementModule, box_iou_loss
from modules.hqsam_feature_extractor import create_hqsam_extractor
from modules.dataset import FungiDataset


class FeatureCache:
    """ç‰¹å¾ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str, split: str = 'train'):
        self.cache_dir = Path(cache_dir) / f"features/{split}"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.split = split
        self.cache_hits = 0
        self.cache_misses = 0
        self.total_requests = 0
    
    def get_cache_path(self, image_path: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        image_hash = hashlib.md5(image_path.encode()).hexdigest()
        return self.cache_dir / f"{image_hash}.npy"
    
    def load_features(self, image_path: str) -> Optional[torch.Tensor]:
        """ä»ç¼“å­˜åŠ è½½ç‰¹å¾"""
        self.total_requests += 1
        cache_path = self.get_cache_path(image_path)
        
        if cache_path.exists():
            try:
                features = np.load(cache_path)
                features_tensor = torch.from_numpy(features)
                self.cache_hits += 1
                return features_tensor
            except Exception as e:
                print(f"Warning: Failed to load cached features from {cache_path}: {e}")
                self.cache_misses += 1
                return None
        else:
            self.cache_misses += 1
            return None
    
    def save_features(self, image_path: str, features: torch.Tensor):
        """ä¿å­˜ç‰¹å¾åˆ°ç¼“å­˜"""
        cache_path = self.get_cache_path(image_path)
        try:
            features_cpu = features.cpu().numpy()
            np.save(cache_path, features_cpu)
        except Exception as e:
            print(f"Warning: Failed to save features to {cache_path}: {e}")
    
    def get_cache_stats(self) -> Dict[str, float]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if self.total_requests == 0:
            return {'hit_rate': 0.0, 'hits': 0, 'misses': 0}
        
        hit_rate = self.cache_hits / self.total_requests
        return {
            'hit_rate': hit_rate,
            'hits': self.cache_hits,
            'misses': self.cache_misses
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self.cache_dir.exists():
            import shutil
            shutil.rmtree(self.cache_dir)
            self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_hits = 0
        self.cache_misses = 0
        self.total_requests = 0


def detect_feature_cache(cache_dir: str) -> bool:
    """æ£€æµ‹æ˜¯å¦å­˜åœ¨ç‰¹å¾ç¼“å­˜"""
    cache_path = Path(cache_dir) / "features"
    return cache_path.exists() and any(cache_path.iterdir())


def extract_features_with_cache(hqsam_extractor, images_np_list, image_paths, feature_cache, device='cuda'):
    """ä½¿ç”¨ç¼“å­˜æå–ç‰¹å¾"""
    features_list = []
    
    for i, (image_np, image_path) in enumerate(zip(images_np_list, image_paths)):
        # å°è¯•ä»ç¼“å­˜åŠ è½½
        if feature_cache is not None:
            cached_features = feature_cache.load_features(image_path)
            if cached_features is not None:
                # ç¡®ä¿ç¼“å­˜çš„ç‰¹å¾åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
                cached_features = cached_features.to(device)
                features_list.append(cached_features)
                continue
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæå–ç‰¹å¾
        features = hqsam_extractor.extract_features(image_np)
        features_list.append(features)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        if feature_cache is not None:
            feature_cache.save_features(image_path, features)
    
    return features_list


def compute_loss(pred_bboxes, gt_bboxes, l1_weight=1.0, iou_weight=2.0):
    """è®¡ç®—æŸå¤±å‡½æ•° - ä¿®å¤ç‰ˆæœ¬"""
    # ç¡®ä¿è¾“å…¥å¼ é‡åœ¨ç›¸åŒè®¾å¤‡ä¸Š
    if pred_bboxes.device != gt_bboxes.device:
        gt_bboxes = gt_bboxes.to(pred_bboxes.device)
    
    # ç¡®ä¿è¾“å…¥å¼ é‡å½¢çŠ¶ä¸€è‡´
    if pred_bboxes.shape != gt_bboxes.shape:
        min_batch = min(pred_bboxes.shape[0], gt_bboxes.shape[0])
        pred_bboxes = pred_bboxes[:min_batch]
        gt_bboxes = gt_bboxes[:min_batch]
    
    # L1æŸå¤±
    l1_loss = F.l1_loss(pred_bboxes, gt_bboxes)
    
    # IoUæŸå¤± - æ·»åŠ æ•°å€¼ç¨³å®šæ€§
    try:
        iou_loss = box_iou_loss(pred_bboxes, gt_bboxes)
        # æ£€æŸ¥IoUæŸå¤±æ˜¯å¦ä¸ºNaNæˆ–Inf
        if torch.isnan(iou_loss) or torch.isinf(iou_loss):
            iou_loss = torch.tensor(0.0, device=pred_bboxes.device)
    except Exception as e:
        print(f"Warning: IoU loss computation failed: {e}")
        iou_loss = torch.tensor(0.0, device=pred_bboxes.device)
    
    # æ€»æŸå¤±
    total_loss = l1_weight * l1_loss + iou_weight * iou_loss
    
    return total_loss, l1_loss, iou_loss


def train_one_epoch(model, dataloader, optimizer, hqsam_extractor, device, epoch, config, 
                   feature_cache=None, use_amp=False):
    """è®­ç»ƒä¸€ä¸ªepoch - ä¿®å¤ç‰ˆæœ¬"""
    model.train()
    
    total_loss = 0.0
    total_l1_loss = 0.0
    total_iou_loss = 0.0
    num_batches = len(dataloader)
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.cuda.amp.GradScaler() if use_amp else None
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch}")
    
    for batch_idx, batch in enumerate(pbar):
        images = batch['images'].to(device)
        gt_bboxes = batch['gt_bboxes'].to(device)
        noisy_bboxes = batch['noisy_bboxes'].to(device)
        image_paths = batch['image_paths']
        
        # æå–ç‰¹å¾
        images_np_list = [img.cpu().numpy().transpose(1, 2, 0) for img in images]
        features_list = extract_features_with_cache(
            hqsam_extractor, images_np_list, image_paths, feature_cache, device
        )
        image_features = torch.cat(features_list, dim=0)  # (B, 256, 64, 64)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        
        if use_amp and scaler is not None:
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            with torch.cuda.amp.autocast():
                # è¿­ä»£ç²¾ç‚¼
                refined_bboxes, history = model.iterative_refine(
                    image_features, noisy_bboxes, (config['data']['image_size'], config['data']['image_size']),
                    max_iter=config['refinement']['max_iter'],
                    stop_threshold=config['refinement']['stop_threshold']
                )
                
                # è®¡ç®—æŸå¤±
                loss, l1_loss, iou_loss = compute_loss(
                    refined_bboxes, gt_bboxes,
                    l1_weight=config['loss']['l1_weight'],
                    iou_weight=config['loss']['iou_weight']
                )
            
            # æ··åˆç²¾åº¦åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            # æ™®é€šç²¾åº¦å‰å‘ä¼ æ’­
            # è¿­ä»£ç²¾ç‚¼
            refined_bboxes, history = model.iterative_refine(
                image_features, noisy_bboxes, (config['data']['image_size'], config['data']['image_size']),
                max_iter=config['refinement']['max_iter'],
                stop_threshold=config['refinement']['stop_threshold']
            )
            
            # è®¡ç®—æŸå¤±
            loss, l1_loss, iou_loss = compute_loss(
                refined_bboxes, gt_bboxes,
                l1_weight=config['loss']['l1_weight'],
                iou_weight=config['loss']['iou_weight']
            )
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
        
        # æ›´æ–°ç»Ÿè®¡
        total_loss += loss.item()
        total_l1_loss += l1_loss.item()
        total_iou_loss += iou_loss.item()
        
        # æ›´æ–°è¿›åº¦æ¡
        cache_stats = feature_cache.get_cache_stats() if feature_cache else {'hit_rate': 0.0}
        pbar.set_postfix({
            'Loss': f'{loss.item():.4f}',
            'L1': f'{l1_loss.item():.4f}',
            'IoU': f'{iou_loss.item():.4f}',
            'Cache': f'Cache: {cache_stats["hit_rate"]:.1%}'
        })
    
    return total_loss / num_batches, total_l1_loss / num_batches, total_iou_loss / num_batches


def evaluate(model, dataloader, hqsam_extractor, device, config, feature_cache=None):
    """è¯„ä¼°æ¨¡å‹ - ä¿®å¤ç‰ˆæœ¬"""
    model.eval()
    
    total_loss = 0.0
    total_l1_loss = 0.0
    total_iou_loss = 0.0
    num_batches = len(dataloader)
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            images = batch['images'].to(device)
            gt_bboxes = batch['gt_bboxes'].to(device)
            noisy_bboxes = batch['noisy_bboxes'].to(device)
            image_paths = batch['image_paths']
            
            # æå–ç‰¹å¾
            images_np_list = [img.cpu().numpy().transpose(1, 2, 0) for img in images]
            features_list = extract_features_with_cache(
                hqsam_extractor, images_np_list, image_paths, feature_cache, device
            )
            image_features = torch.cat(features_list, dim=0)
            
            # å‰å‘ä¼ æ’­
            refined_bboxes, history = model.iterative_refine(
                image_features, noisy_bboxes, (config['data']['image_size'], config['data']['image_size']),
                max_iter=config['refinement']['max_iter'],
                stop_threshold=config['refinement']['stop_threshold']
            )
            
            # è®¡ç®—æŸå¤±
            loss, l1_loss, iou_loss = compute_loss(
                refined_bboxes, gt_bboxes,
                l1_weight=config['loss']['l1_weight'],
                iou_weight=config['loss']['iou_weight']
            )
            
            total_loss += loss.item()
            total_l1_loss += l1_loss.item()
            total_iou_loss += iou_loss.item()
    
    return total_loss / num_batches, total_l1_loss / num_batches, total_iou_loss / num_batches


def main():
    """ä¸»å‡½æ•° - ä¿®å¤ç‰ˆæœ¬"""
    parser = argparse.ArgumentParser(description='Box Refinement Training - Fixed Version')
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, default='auto', help='è®¾å¤‡é€‰æ‹©')
    parser.add_argument('--fast', action='store_true', help='å¿«é€Ÿæ¨¡å¼')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…ç©ºç‰¹å¾ç¼“å­˜')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å¿«é€Ÿæ¨¡å¼è®¾ç½®
    if args.fast:
        print("ğŸš€ Fast mode enabled - applying all optimizations")
        config['data']['sample_ratio'] = 0.1
        config['training']['use_amp'] = True
        config['training']['batch_size'] = 32
        print(f"  - Data sampling: {config['data']['sample_ratio']}")
        print(f"  - Mixed precision: {config['training']['use_amp']}")
        print(f"  - Batch size: {config['training']['batch_size']}")
    
    # è®¾å¤‡é€‰æ‹©
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    print(f"Using device: {device}")
    
    # æ£€æµ‹ç‰¹å¾ç¼“å­˜
    cache_detected = detect_feature_cache(config['output']['checkpoint_dir'])
    print(f"Feature cache detected: {cache_detected}")
    
    # åˆ›å»ºç‰¹å¾ç¼“å­˜
    feature_cache = FeatureCache(config['output']['checkpoint_dir']) if config['training']['feature_cache'] else None
    
    # æ¸…ç©ºç¼“å­˜
    if args.clear_cache and feature_cache is not None:
        print("Clearing feature cache...")
        feature_cache.clear_cache()
        print("Feature cache cleared.")
    
    # åŠ è½½æ•°æ®é›†
    print("Loading datasets...")
    train_dataset = FungiDataset(
        data_root=config['data']['data_root'],
        split=config['data']['train_split'],
        image_size=config['data']['image_size'],
        data_subset=config['data']['data_subset'],
        augmentation=config['data']['augmentation']['enabled'],
        debug=args.debug,
        sample_ratio=config['data']['sample_ratio']
    )
    
    val_dataset = FungiDataset(
        data_root=config['data']['data_root'],
        split=config['data']['val_split'],
        image_size=config['data']['image_size'],
        data_subset=config['data']['data_subset'],
        augmentation=False,
        debug=args.debug,
        sample_ratio=config['data']['sample_ratio']
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("Creating model...")
    model = BoxRefinementModule(
        hidden_dim=config['model']['hidden_dim'],
        num_heads=config['model']['num_heads'],
        max_offset=config['model']['max_offset']
    ).to(device)
    
    # åˆ›å»ºHQ-SAMç‰¹å¾æå–å™¨
    print("Loading HQ-SAM feature extractor...")
    hqsam_extractor = create_hqsam_extractor(
        checkpoint_path=config['hqsam']['checkpoint_path'],
        model_type=config['hqsam']['model_type'],
        device=device,
        use_mock=True  # ä½¿ç”¨Mockç‰ˆæœ¬è¿›è¡Œæµ‹è¯•
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨ - ä¿®å¤å­¦ä¹ ç‡
    print("Creating optimizer...")
    learning_rate = float(config['training']['learning_rate'])
    if args.fast:
        learning_rate *= 2  # å¿«é€Ÿæ¨¡å¼ä¸‹ç¨å¾®æé«˜å­¦ä¹ ç‡
    
    optimizer = optim.Adam(
        model.parameters(),
        lr=learning_rate,
        weight_decay=float(config['training']['weight_decay'])
    )
    
    print(f"Learning rate: {learning_rate}")
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    if config['training']['lr_scheduler'] == 'cosine':
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=config['training']['epochs']
        )
    else:
        scheduler = None
    
    # è®­ç»ƒå¾ªç¯
    print("Starting training...")
    best_val_loss = float('inf')
    train_losses = []
    val_losses = []
    
    for epoch in range(config['training']['epochs']):
        # è®­ç»ƒ
        train_loss, train_l1, train_iou = train_one_epoch(
            model, train_loader, optimizer, hqsam_extractor, device, epoch, config,
            feature_cache=feature_cache, use_amp=config['training']['use_amp']
        )
        
        # éªŒè¯
        val_loss, val_l1, val_iou = evaluate(
            model, val_loader, hqsam_extractor, device, config, feature_cache=feature_cache
        )
        
        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler is not None:
            scheduler.step()
        
        # è®°å½•æŸå¤±
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
        print(f"  Train L1: {train_l1:.4f}, IoU: {train_iou:.4f}")
        print(f"  Val L1: {val_l1:.4f}, IoU: {val_iou:.4f}")
        
        # ç¼“å­˜ç»Ÿè®¡
        if feature_cache is not None:
            cache_stats = feature_cache.get_cache_stats()
            print(f"  Cache hit rate: {cache_stats['hit_rate']:.1%}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': train_loss,
                'val_loss': val_loss,
            }, os.path.join(config['output']['checkpoint_dir'], 'best_model.pth'))
            print(f"  New best model saved! Val Loss: {val_loss:.4f}")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    torch.save({
        'epoch': config['training']['epochs'] - 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'train_loss': train_loss,
        'val_loss': val_loss,
    }, os.path.join(config['output']['checkpoint_dir'], 'final_model.pth'))
    
    print("Training completed!")
    print(f"Best validation loss: {best_val_loss:.4f}")
    
    # æ‰“å°ç¼“å­˜ç»Ÿè®¡
    if feature_cache is not None:
        cache_stats = feature_cache.get_cache_stats()
        print(f"Final cache hit rate: {cache_stats['hit_rate']:.1%}")
        print(f"Total cache hits: {cache_stats['hits']}")
        print(f"Total cache misses: {cache_stats['misses']}")


if __name__ == "__main__":
    main()