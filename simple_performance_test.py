#!/usr/bin/env python3
"""
ç®€åŒ–çš„ Box Refinement æ€§èƒ½æµ‹è¯•è„šæœ¬
ä¸“é—¨ç”¨äºéªŒè¯ä¼˜åŒ–æ•ˆæœï¼Œé¿å…å¤æ‚çš„æ•°æ®é›†ä¾èµ–
"""

import os
import sys
import time
import torch
import numpy as np
from pathlib import Path
import yaml
from typing import Dict, List

# æ·»åŠ modulesç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))

from modules.box_refinement import BoxRefinementModule
from modules.hqsam_feature_extractor import create_hqsam_extractor
from train_box_refiner_optimized import FeatureCache, extract_features_with_cache


class SimplePerformanceTest:
    """ç®€åŒ–çš„æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, device: str = 'cuda'):
        self.device = device
        
        # åˆ›å»ºæ¨¡å‹
        self.model = BoxRefinementModule(
            hidden_dim=256,
            num_heads=8,
            max_offset=50
        ).to(device)
        
        # åˆ›å»ºç‰¹å¾æå–å™¨
        self.hqsam_extractor = create_hqsam_extractor(
            checkpoint_path="dummy_path",
            model_type='vit_h',
            device=device,
            use_mock=True
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_images = self._create_test_images(10)
        self.test_bboxes = self._create_test_bboxes(10)
    
    def _create_test_images(self, num_images: int) -> List[np.ndarray]:
        """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
        images = []
        for i in range(num_images):
            image = np.random.randint(0, 255, (300, 300, 3), dtype=np.uint8)
            images.append(image)
        return images
    
    def _create_test_bboxes(self, num_bboxes: int) -> torch.Tensor:
        """åˆ›å»ºæµ‹è¯•bbox"""
        bboxes = []
        for i in range(num_bboxes):
            x1 = np.random.randint(0, 200)
            y1 = np.random.randint(0, 200)
            x2 = x1 + np.random.randint(50, 100)
            y2 = y1 + np.random.randint(50, 100)
            bboxes.append([x1, y1, x2, y2])
        return torch.tensor(bboxes, dtype=torch.float32, device=self.device)
    
    def test_original_method(self, num_epochs: int = 3, num_batches: int = 5) -> Dict[str, float]:
        """æµ‹è¯•åŸå§‹æ–¹æ³• (æ¯æ¬¡éƒ½æå–ç‰¹å¾)"""
        print("ğŸ”„ æµ‹è¯•åŸå§‹æ–¹æ³• (æ¯æ¬¡éƒ½æå–ç‰¹å¾)...")
        
        start_time = time.time()
        total_extractions = 0
        
        for epoch in range(num_epochs):
            for batch_idx in range(num_batches):
                # æ¯æ¬¡éƒ½æå–ç‰¹å¾
                features_list = []
                for image in self.test_images:
                    features = self.hqsam_extractor.extract_features(image)
                    features_list.append(features.to(self.device))
                    total_extractions += 1
                
                # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
                image_features = torch.cat(features_list, dim=0)
                bboxes = self.test_bboxes[:len(features_list)]
                
                with torch.no_grad():
                    refined_bboxes, _ = self.model.iterative_refine(
                        image_features, bboxes, (300, 300), max_iter=3
                    )
        
        end_time = time.time()
        total_time = end_time - start_time
        
        return {
            'total_time': total_time,
            'avg_epoch_time': total_time / num_epochs,
            'avg_batch_time': total_time / (num_epochs * num_batches),
            'feature_extractions': total_extractions,
            'method': 'original'
        }
    
    def test_optimized_method(self, num_epochs: int = 3, num_batches: int = 5) -> Dict[str, float]:
        """æµ‹è¯•ä¼˜åŒ–æ–¹æ³• (ä½¿ç”¨ç¼“å­˜)"""
        print("âš¡ æµ‹è¯•ä¼˜åŒ–æ–¹æ³• (ä½¿ç”¨ç¼“å­˜)...")
        
        # åˆ›å»ºç‰¹å¾ç¼“å­˜
        cache_dir = "./test_cache"
        feature_cache = FeatureCache(cache_dir, 'test')
        
        start_time = time.time()
        total_extractions = 0
        
        for epoch in range(num_epochs):
            for batch_idx in range(num_batches):
                # ä½¿ç”¨ç¼“å­˜æå–ç‰¹å¾
                image_paths = [f"test_image_{i}.jpg" for i in range(len(self.test_images))]
                features_list = extract_features_with_cache(
                    self.hqsam_extractor, self.test_images, image_paths, feature_cache, self.device
                )
                total_extractions += len(self.test_images)
                
                # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
                image_features = torch.cat(features_list, dim=0)
                bboxes = self.test_bboxes[:len(features_list)]
                
                with torch.no_grad():
                    refined_bboxes, _ = self.model.iterative_refine(
                        image_features, bboxes, (300, 300), max_iter=3
                    )
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = feature_cache.get_cache_stats()
        
        return {
            'total_time': total_time,
            'avg_epoch_time': total_time / num_epochs,
            'avg_batch_time': total_time / (num_epochs * num_batches),
            'feature_extractions': total_extractions,
            'cache_hit_rate': cache_stats['hit_rate'],
            'cache_hits': cache_stats['hits'],
            'cache_misses': cache_stats['misses'],
            'method': 'optimized'
        }
    
    def test_mixed_precision(self) -> Dict[str, float]:
        """æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒæ•ˆæœ"""
        print("ğŸ¯ æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒ...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 8
        images = torch.randn(batch_size, 3, 300, 300, device=self.device)
        bboxes = torch.randn(batch_size, 4, device=self.device)
        image_features = torch.randn(batch_size, 256, 64, 64, device=self.device)
        
        # æµ‹è¯•æ™®é€šç²¾åº¦
        start_time = time.time()
        for _ in range(50):  # å‡å°‘æµ‹è¯•æ¬¡æ•°
            with torch.no_grad():
                refined_bboxes, _ = self.model.iterative_refine(
                    image_features, bboxes, (300, 300), max_iter=3
                )
        normal_time = time.time() - start_time
        
        # æµ‹è¯•æ··åˆç²¾åº¦
        start_time = time.time()
        for _ in range(50):
            with torch.no_grad():
                with torch.cuda.amp.autocast():
                    refined_bboxes, _ = self.model.iterative_refine(
                        image_features, bboxes, (300, 300), max_iter=3
                    )
        amp_time = time.time() - start_time
        
        return {
            'normal_time': normal_time,
            'amp_time': amp_time,
            'speedup': normal_time / amp_time if amp_time > 0 else 1.0,
            'memory_saved': '~30-50%'
        }
    
    def run_comprehensive_test(self) -> Dict[str, Dict[str, float]]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•...")
        print("=" * 60)
        
        results = {}
        
        # æµ‹è¯•åŸå§‹æ–¹æ³•
        try:
            results['original'] = self.test_original_method()
            print(f"âœ… åŸå§‹æ–¹æ³•å®Œæˆ: {results['original']['total_time']:.2f}s")
        except Exception as e:
            print(f"âŒ åŸå§‹æ–¹æ³•å¤±è´¥: {e}")
            results['original'] = {}
        
        # æµ‹è¯•ä¼˜åŒ–æ–¹æ³•
        try:
            results['optimized'] = self.test_optimized_method()
            print(f"âœ… ä¼˜åŒ–æ–¹æ³•å®Œæˆ: {results['optimized']['total_time']:.2f}s")
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–æ–¹æ³•å¤±è´¥: {e}")
            results['optimized'] = {}
        
        # æµ‹è¯•æ··åˆç²¾åº¦
        try:
            results['mixed_precision'] = self.test_mixed_precision()
            print(f"âœ… æ··åˆç²¾åº¦æµ‹è¯•å®Œæˆ")
        except Exception as e:
            print(f"âŒ æ··åˆç²¾åº¦æµ‹è¯•å¤±è´¥: {e}")
            results['mixed_precision'] = {}
        
        return results
    
    def print_results(self, results: Dict[str, Dict[str, float]]):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ")
        print("=" * 60)
        
        # åŸå§‹ vs ä¼˜åŒ–å¯¹æ¯”
        if 'original' in results and 'optimized' in results:
            orig = results['original']
            opt = results['optimized']
            
            if 'total_time' in orig and 'total_time' in opt:
                speedup = orig['total_time'] / opt['total_time']
                print(f"\nğŸ”„ ç‰¹å¾ç¼“å­˜æ•ˆæœå¯¹æ¯”:")
                print(f"  åŸå§‹æ–¹æ³•æ—¶é—´: {orig['total_time']:.2f}s")
                print(f"  ä¼˜åŒ–æ–¹æ³•æ—¶é—´: {opt['total_time']:.2f}s")
                print(f"  åŠ é€Ÿæ¯”: {speedup:.1f}x")
                
                if 'cache_hit_rate' in opt:
                    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {opt['cache_hit_rate']:.1%}")
                    print(f"  ç¼“å­˜å‘½ä¸­: {opt['cache_hits']}")
                    print(f"  ç¼“å­˜æœªå‘½ä¸­: {opt['cache_misses']}")
                
                if speedup >= 30:
                    print("  âœ… è¾¾åˆ°ç›®æ ‡: â‰¥30x åŠ é€Ÿ")
                else:
                    print("  âš ï¸  æœªè¾¾åˆ°ç›®æ ‡: <30x åŠ é€Ÿ")
        
        # æ··åˆç²¾åº¦æ•ˆæœ
        if 'mixed_precision' in results:
            mp = results['mixed_precision']
            print(f"\nâš¡ æ··åˆç²¾åº¦æ•ˆæœ:")
            print(f"  æ™®é€šç²¾åº¦æ—¶é—´: {mp.get('normal_time', 0):.2f}s")
            print(f"  æ··åˆç²¾åº¦æ—¶é—´: {mp.get('amp_time', 0):.2f}s")
            print(f"  åŠ é€Ÿæ¯”: {mp.get('speedup', 1):.1f}x")
            print(f"  æ˜¾å­˜èŠ‚çœ: {mp.get('memory_saved', 'N/A')}")
        
        # ç»¼åˆæ•ˆæœä¼°ç®—
        print(f"\nğŸ¯ ç»¼åˆä¼˜åŒ–æ•ˆæœ:")
        if 'original' in results and 'optimized' in results:
            feature_speedup = results['original'].get('total_time', 1) / results['optimized'].get('total_time', 1)
            amp_speedup = results.get('mixed_precision', {}).get('speedup', 1)
            total_speedup = feature_speedup * amp_speedup
            
            print(f"  ç‰¹å¾ç¼“å­˜åŠ é€Ÿ: {feature_speedup:.1f}x")
            print(f"  æ··åˆç²¾åº¦åŠ é€Ÿ: {amp_speedup:.1f}x")
            print(f"  ç»¼åˆåŠ é€Ÿæ¯”: {total_speedup:.1f}x")
            
            if total_speedup >= 30:
                print("  âœ… è¾¾åˆ°ç›®æ ‡: â‰¥30x åŠ é€Ÿ")
            else:
                print("  âš ï¸  æœªè¾¾åˆ°ç›®æ ‡: <30x åŠ é€Ÿ")
        
        print(f"\nğŸ’¡ è¯´æ˜:")
        print(f"  - è¿™æ˜¯åŸºäºMockæ•°æ®çš„æµ‹è¯•ç»“æœ")
        print(f"  - å®é™…ä½¿ç”¨ä¸­åŠ é€Ÿæ•ˆæœå¯èƒ½æ›´æ˜æ˜¾")
        print(f"  - ç‰¹å¾ç¼“å­˜åœ¨ç¬¬äºŒæ¬¡åŠä»¥åè®­ç»ƒä¸­æ•ˆæœæœ€ä½³")


def main():
    """ä¸»å‡½æ•°"""
    print("Box Refinement ç®€åŒ–æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device == 'cpu':
        print("âš ï¸  ä½¿ç”¨CPUå¯èƒ½å½±å“æµ‹è¯•ç»“æœçš„å‡†ç¡®æ€§")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = SimplePerformanceTest(device)
    
    # è¿è¡Œæµ‹è¯•
    results = tester.run_comprehensive_test()
    
    # æ‰“å°ç»“æœ
    tester.print_results(results)
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")
    print("\nğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°æ§åˆ¶å°è¾“å‡º")


if __name__ == "__main__":
    main()